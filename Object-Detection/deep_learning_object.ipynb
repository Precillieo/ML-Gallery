{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kGaRQO6_Fb2"
      },
      "source": [
        "#Import the Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhKAYckg-QWT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import argparse\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grp_YXmP_PJS"
      },
      "source": [
        "#Construct the argument parse and parse the arguments\n",
        "\n",
        "Using the argumentpasrer for parsing the images \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AV848mGH-2vj"
      },
      "outputs": [],
      "source": [
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-i\", \"--image\", required=True,\n",
        "\thelp=\"path to input image\")\n",
        "ap.add_argument(\"-p\", \"--prototxt\", required=True,\n",
        "\thelp=\"path to Caffe 'deploy' prototxt file\")\n",
        "ap.add_argument(\"-m\", \"--model\", required=True,\n",
        "\thelp=\"path to Caffe pre-trained model\")\n",
        "ap.add_argument(\"-c\", \"--confidence\", type=float, default=0.2,\n",
        "\thelp=\"minimum probability to filter weak detections\")\n",
        "args = vars(ap.parse_args())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLQQJs5N_eKO"
      },
      "source": [
        "# Initialize the list of class labels MobileNet SSD was trained to detect, then generate a set of bounding box colors for each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffGACGs6-2sD"
      },
      "outputs": [],
      "source": [
        "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
        "\t\"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
        "\t\"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
        "\t\"sofa\", \"train\", \"tvmonitor\"]\n",
        "COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHoqbt56_nhz"
      },
      "source": [
        "# Load our serialized model from disk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zsjx4AJ7-2oj"
      },
      "outputs": [],
      "source": [
        "print(\"[INFO] loading model...\")\n",
        "net = cv2.dnn.readNetFromCaffe(args[\"prototxt\"], args[\"model\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuodODqRBAhz"
      },
      "source": [
        "##Load the input image and construct an input blob for the image by resizing to a fixed 300x300 pixels and then normalizing it\n",
        "## (note: normalization is done via the authors of the MobileNet SSD\n",
        "##implementation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7M1ltmVZ-2d0"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread(args[\"image\"])\n",
        "(h, w) = image.shape[:2]\n",
        "blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 0.007843, (300, 300), 127.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5pbeUfDBLLW"
      },
      "source": [
        "##pass the blob through the network and obtain the detections and\n",
        "## predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykBVMwtt-12N"
      },
      "outputs": [],
      "source": [
        "print(\"[INFO] computing object detections...\")\n",
        "net.setInput(blob)\n",
        "detections = net.forward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RA5w9NhEjX1S"
      },
      "source": [
        "Now This is the main Part where  we loop the Detection we have made.\n",
        "While looping we need the less filtered images or images with noise to be filtered out so we have taken an if loop to check the confidence.\n",
        "\n",
        "After filtering out through confidence we have to display the labels and printing the detction we have made."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ur4ujBVv-10l"
      },
      "outputs": [],
      "source": [
        "for i in np.arange(0, detections.shape[2]):\n",
        "\t# extract the confidence (i.e., probability) associated with the\n",
        "\t# prediction\n",
        "\tconfidence = detections[0, 0, i, 2]\n",
        "\n",
        "\t# filter out weak detections by ensuring the `confidence` is\n",
        "\t# greater than the minimum confidence\n",
        "\tif confidence > args[\"confidence\"]:\n",
        "\t\t# extract the index of the class label from the `detections`,\n",
        "\t\t# then compute the (x, y)-coordinates of the bounding box for\n",
        "\t\t# the object\n",
        "\t\tidx = int(detections[0, 0, i, 1])\n",
        "\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "\t\t# display the prediction\n",
        "\t\tlabel = \"{}: {:.2f}%\".format(CLASSES[idx], confidence * 100)\n",
        "\t\tprint(\"[INFO] {}\".format(label))\n",
        "\t\tcv2.rectangle(image, (startX, startY), (endX, endY),\n",
        "\t\t\tCOLORS[idx], 2)\n",
        "\t\ty = startY - 15 if startY - 15 > 15 else startY + 15\n",
        "\t\tcv2.putText(image, label, (startX, y),\n",
        "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrgsoL9C-1kW"
      },
      "outputs": [],
      "source": [
        "cv2.imshow(\"Output\", image)\n",
        "cv2.waitKey(0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRW9YJkOAOQb"
      },
      "source": [
        "##To run this file we need all the images input and simultaneously use Pre trained model to work so we  can run this command in terminal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmgxD7cZ-06Y"
      },
      "outputs": [],
      "source": [
        "#python deep_learning_object_detection.py --image images/example_01.jpg --prototxt MobileNetSSD_deploy.prototxt.txt --model MobileNetSSD_deploy.caffemodel"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Object Detction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
